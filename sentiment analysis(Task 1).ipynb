{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2d45635",
   "metadata": {},
   "source": [
    "# Import the necessary libraries and download the required nltk data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d4c5008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Shahzaib\n",
      "[nltk_data]     Khan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# download the required nltk data\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f34c09f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified |  At Copenhagen the most chaotic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Worst experience of my life trying to deal wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Due to code sharing with Cathay Pacific I was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LHR check in was quick at the First Wing and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I wouldn't recommend British Airways at all. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>Flight from Heathrow to Toronto. Booked emerge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>LHR to HAM. Purser addresses all club passenge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>My son who had worked for British Airways urge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>London City-New York JFK via Shannon on A318 b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>SIN-LHR BA12 B747-436 First Class. Old aircraf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3530 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_reviews\n",
       "0     Not Verified |  At Copenhagen the most chaotic...\n",
       "1      Worst experience of my life trying to deal wi...\n",
       "2      Due to code sharing with Cathay Pacific I was...\n",
       "3      LHR check in was quick at the First Wing and ...\n",
       "4      I wouldn't recommend British Airways at all. ...\n",
       "...                                                 ...\n",
       "3525  Flight from Heathrow to Toronto. Booked emerge...\n",
       "3526  LHR to HAM. Purser addresses all club passenge...\n",
       "3527  My son who had worked for British Airways urge...\n",
       "3528  London City-New York JFK via Shannon on A318 b...\n",
       "3529  SIN-LHR BA12 B747-436 First Class. Old aircraf...\n",
       "\n",
       "[3530 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = pd.read_csv(\"Clean reviews.csv\").drop(\"Unnamed: 0\",axis=1)\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cee3a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4412fce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified |  At Copenhagen the most chaotic...</td>\n",
       "      <td>0.1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Worst experience of my life trying to deal wi...</td>\n",
       "      <td>-0.9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Due to code sharing with Cathay Pacific I was...</td>\n",
       "      <td>-0.8510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LHR check in was quick at the First Wing and ...</td>\n",
       "      <td>0.9251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I wouldn't recommend British Airways at all. ...</td>\n",
       "      <td>-0.9372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>Flight from Heathrow to Toronto. Booked emerge...</td>\n",
       "      <td>0.8608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>LHR to HAM. Purser addresses all club passenge...</td>\n",
       "      <td>0.8720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>My son who had worked for British Airways urge...</td>\n",
       "      <td>0.6640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>London City-New York JFK via Shannon on A318 b...</td>\n",
       "      <td>0.9148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>SIN-LHR BA12 B747-436 First Class. Old aircraf...</td>\n",
       "      <td>0.2244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3530 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_reviews  sentiment\n",
       "0     Not Verified |  At Copenhagen the most chaotic...     0.1015\n",
       "1      Worst experience of my life trying to deal wi...    -0.9600\n",
       "2      Due to code sharing with Cathay Pacific I was...    -0.8510\n",
       "3      LHR check in was quick at the First Wing and ...     0.9251\n",
       "4      I wouldn't recommend British Airways at all. ...    -0.9372\n",
       "...                                                 ...        ...\n",
       "3525  Flight from Heathrow to Toronto. Booked emerge...     0.8608\n",
       "3526  LHR to HAM. Purser addresses all club passenge...     0.8720\n",
       "3527  My son who had worked for British Airways urge...     0.6640\n",
       "3528  London City-New York JFK via Shannon on A318 b...     0.9148\n",
       "3529  SIN-LHR BA12 B747-436 First Class. Old aircraf...     0.2244\n",
       "\n",
       "[3530 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply sentiment analysis to each row of the \"clean_reviews\" column\n",
    "Data['sentiment'] = Data['clean_reviews'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1678a3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentiment polarity score: 0.1792445609065156\n"
     ]
    }
   ],
   "source": [
    "average_sentiment = Data['sentiment'].mean()\n",
    "print('Average sentiment polarity score:', average_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75262812",
   "metadata": {},
   "source": [
    "# Tokenize the \"clean_reviews\" column of the DataFrame and remove stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99db6543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tokenizer object\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create a list of stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# define a function to tokenize and remove stopwords\n",
    "def preprocess(text):\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# apply the preprocessing function to each review in the \"clean_reviews\" column\n",
    "Data['tokens'] = Data['clean_reviews'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a369d22",
   "metadata": {},
   "source": [
    "# Create a dictionary and a corpus for topic modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "905ccb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary from the tokens\n",
    "dictionary = corpora.Dictionary(Data['tokens'])\n",
    "\n",
    "# create a corpus from the dictionary and the tokens\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in Data['tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb726102",
   "metadata": {},
   "source": [
    "# Train an LDA model on the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f51190b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train an LDA model on the corpus\n",
    "num_topics = 10\n",
    "lda_model = gensim.models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a6978a",
   "metadata": {},
   "source": [
    "# Analyze the topics by printing the top words in each topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "332bf626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: flight ba time staff london crew food service seat heathrow\n",
      "Topic 1: ba flight seat food time service economy airways would british\n",
      "Topic 2: flight good ba food crew seats cabin service seat time\n",
      "Topic 3: british ba airways service flight get business london class crew\n",
      "Topic 4: flight ba class airways service economy food seats one staff\n",
      "Topic 5: flight ba seat service business airways british would good meal\n",
      "Topic 6: flight crew food cabin ba service boarding good seats would\n",
      "Topic 7: flight ba us staff would cabin check british food airways\n",
      "Topic 8: flight ba service airways british time seats seat food class\n",
      "Topic 9: flight ba seat service seats get lhr class time one\n"
     ]
    }
   ],
   "source": [
    "# print the top words in each topic\n",
    "for topic_id in range(num_topics):\n",
    "    words = lda_model.show_topic(topic_id, topn=10)\n",
    "    topic = f\"Topic {topic_id}: {' '.join([word[0] for word in words])}\"\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa1ef23",
   "metadata": {},
   "source": [
    "## These topics suggest that the dataset primarily contains reviews of British Airways flights to/from London, with a focus on various aspects such as the quality of service, the seats and cabin, the food, and the business class experience.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a231b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
